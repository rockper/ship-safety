{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:black\">\n",
    "    <h3>Start Redis Server before running:</h3>\n",
    "    <p><b>&dollar; sudo systemctl status redis-server &nbsp; # To check if it's running</b></p>\n",
    "    <p><b>&dollar; sudo systemctl start redis-server &nbsp; # To start it</b></p>\n",
    "    <p><b>&dollar; redis-server /etc/redis/redis.conf &nbsp; # To start it manually</b></p>\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "import itertools\n",
    "import os\n",
    "from calendar import monthrange\n",
    "from random import randint\n",
    "\n",
    "# from google.cloud import bigquery\n",
    "import geopandas as gpd\n",
    "import ml2rt  # for loading and serializing models\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyarrow.parquet as pq\n",
    "import redis\n",
    "from geopy.distance import distance\n",
    "from ipyleaflet import Map, basemaps, basemap_to_tiles, Polyline, Polygon, Circle, Rectangle, LayerGroup, LayersControl\n",
    "from palettable.lightbartlein.sequential import Blues10_4  # For Shipping Lanes\n",
    "from palettable.cartocolors.qualitative import Bold_10, Pastel_10  # For ships & tracks\n",
    "from redisearch import Client, TextField, NumericField, Query\n",
    "\n",
    "# All three Redis modules have a constructor named \"Client\". \n",
    "# To avoid name clashes, import the modules just before you need them\n",
    "# from redistimeseries.client import Client\n",
    "# from redisai import Client, DType, Tensor, Backend, Device\n",
    "\n",
    "CODE_DIR = \"/media/rock/x/data/ais_20180921/\"\n",
    "DATA_DIR = CODE_DIR + \"output/\"\n",
    "os.chdir(CODE_DIR)\n",
    "\n",
    "## os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = \"/media/rock/x/data/ais_20180921/ais-bigquery-sa.json\"\n",
    "## client = bigquery.Client()\n",
    "## dataset_id = 'by_ymd_3m'  # for BigQuery\n",
    "# https://googleapis.dev/python/bigquery/latest/index.html\n",
    "\n",
    "r = redis.Redis()\n",
    "# r = redis.Redis(host='localhost', port=6379, db=0, password=None, socket_timeout=None)\n",
    "# https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Timestamp.html\n",
    "\n",
    "esri_satellite_layer = basemap_to_tiles(bm=basemaps.Esri.WorldImagery)\n",
    "GOOGLE_MAPS_API_KEY = \"xxxxxxxxxxxxxxx\"\n",
    "# jupyter nbextension enable --py --sys-prefix ipyleaflet  # For Jupyter Notebook\n",
    "# jupyter labextension install @jupyter-widgets/jupyterlab-manager jupyter-leaflet  # for JupyterLab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<span style=\"color:blue\">\n",
    "    <h2><b>BigQuery</b></h2>\n",
    "    <p><b>BigQuery can read partitioned parquet datasets that were produced in Spark</b></p>\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# INCOMPLETE\n",
    "# https://cloud.google.com/bigquery/docs/loading-data-cloud-storage-parquet\n",
    "dataset_ref = client.dataset(dataset_id)\n",
    "job_config = bigquery.LoadJobConfig()\n",
    "job_config.source_format = bigquery.SourceFormat.PARQUET\n",
    "uri = \"gs://ais-rmp/output/by_ymd_3m_pqt/\"\n",
    "\n",
    "load_job = client.load_table_from_uri(uri, dataset_ref.table(\"by_ymd_3m\"), job_config=job_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<span style=\"color:blue\">\n",
    "    <h2><b>PyArrow, Pandas</b></h2>\n",
    "    <p><b>PyArrow can read partitioned parquet datasets on the desktop</b></p>\n",
    "    <p><b>The dataset is a directory named \"by_ymd_3m\", with nested subdirectories for year, month, and day.</b></p>\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def vessels_one_minute(y, m, d, H, M, S):\n",
    "    \"\"\"\n",
    "    Returns a dataframe of vessels in Puget Sound at the specified time\n",
    "    \"\"\"\n",
    "    DIR = DATA_DIR + \"by_ymd_3m_pqt\" + \"/year=\" + str(y) + \"/month=\" + str(m) + \"/day=\" + str(d)\n",
    "    df = pq.read_table(DIR).to_pandas()  # Create a pandas dataframe from the pyarrow table\n",
    "    vessels_minute = df.loc[(df['localtime'] > pd.Timestamp(year=y, month=m, day=d, hour=H, minute=M-1, second=S)) & \n",
    "                            (df['localtime'] <= pd.Timestamp(year=y, month=m, day=d, hour=H, minute=M, second=S))]\n",
    "    return vessels_minute\n",
    "\n",
    "\n",
    "def vessels_one_hour(y, m, d, H, M, S):\n",
    "    \"\"\"\n",
    "    Returns a dataframe of vessels in Puget Sound at the specified time\n",
    "    This dataframe is used in the RedisTimeSeries section\n",
    "    \"\"\"\n",
    "    DIR = DATA_DIR + \"by_ymd_3m_pqt\" + \"/year=\" + str(y) + \"/month=\" + str(m) + \"/day=\" + str(d)\n",
    "    df = pq.read_table(DIR).to_pandas()\n",
    "    vessels_hour = df.loc[(df['localtime'] > pd.Timestamp(year=y, month=m, day=d, hour=H-1, minute=M, second=S)) & \n",
    "                            (df['localtime'] <= pd.Timestamp(year=y, month=m, day=d, hour=H, minute=M, second=S))]\n",
    "    return vessels_hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def create_geokey(keyname, df):\n",
    "    \"\"\"\n",
    "    Creates a Geospatial key from a DataFrame, df.\n",
    "    Returns nothing\n",
    "    \"\"\"\n",
    "    lonlatnames = [[df['lon'].iloc[row], df['lat'].iloc[row], str(df['mmsi'].iloc[row])] for row in range(len(df.index))]\n",
    "    concat_list = list(itertools.chain(*lonlatnames))\n",
    "    r.geoadd(keyname, *concat_list)\n",
    "    return\n",
    "\n",
    "\n",
    "def get_vessel_metadata(mmsi):\n",
    "    return vessels.loc[vessels.mmsi == mmsi]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Select a random time point in 3 months / 3 years. Pick 1 minute / 1 hour of data before that time point.\n",
    "y = 2017\n",
    "m = randint(10, 12)\n",
    "d = randint(1, monthrange(y,m)[1])\n",
    "H = randint(1, 23)\n",
    "M = randint(0, 59)\n",
    "S = randint(0, 59)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "y,m,d,H,M,S\n",
    "# vessels_one_hour(2017, 11, 3, 17, 58, 35)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<span style=\"color:black\">\n",
    "    <h3>Read Metadata</h3>\n",
    "    <p><b>Attributes for each vessel</b></p>\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# RUN: Read the metadata file which has \"vessel_group\" column added\n",
    "col_names = ['mmsi', 'vessel_code', 'vessel_name', 'imo', 'call_sign', 'l', 'w', 'draft', 'cargo', 'vessel_group']\n",
    "types = ['int32', 'category', 'object', 'object', 'object', 'float64', 'float64', 'float64', 'category', 'category']\n",
    "col_dtypes = dict(zip(col_names, types))\n",
    "\n",
    "metadata_file = DATA_DIR + 'metadata_vg_3m.csv'  # !!! CHANGE for 3 months <==> 3 years\n",
    "# metadata_file = DATA_DIR + 'metadata_vg_3y.csv'  # !!! CHANGE for 3 months <==> 3 years\n",
    "\n",
    "vessels = pd.read_csv(metadata_file, header=0, names=col_names, dtype=col_dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "vgroup2color = {'pleasure': Bold_10.hex_colors[7], \n",
    "                'publicService': \"red\", \n",
    "                'passenger': Bold_10.hex_colors[1], \n",
    "                'cargo': Bold_10.hex_colors[8], \n",
    "                'tanker': Bold_10.hex_colors[3], \n",
    "                'fishing': Blues10_4.hex_colors[0], \n",
    "                'tugTow': Bold_10.hex_colors[6],  \n",
    "                'military': \"olive\", \n",
    "                'research': \"violet\",\n",
    "                'unknown': \"white\"\n",
    "               }\n",
    "\n",
    "vgroups = list(vgroup2color.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<span style=\"color:black\">\n",
    "    <h3>Read Motion data from Parquet</h3>\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "vm = vessels_one_minute(y, m, d, H, M, S)\n",
    "# vm = vessels_one_minute(2017, 11, 3, 17, 58, 35)\n",
    "vm_moving = vm.loc[vm['sog'] >= 4]\n",
    "vm_stationary = vm.loc[vm['sog'] < 4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<span style=\"color:black\">\n",
    "    <h3>Create Geospatial Keys in Redis</h3>\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# DO NOT RUN if Keys already exist\n",
    "create_geokey(\"moving\", vm_moving)\n",
    "create_geokey(\"stationary\", vm_stationary)\n",
    "create_geokey(\"all\", vm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<span style=\"color:black\">\n",
    "    <h3>Get the MMSIs for the moving vessels from the Sorted Set</h3>\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "moving_mmsis = [mmsi.decode(\"utf-8\") for mmsi in r.zrange(\"moving\", 0, -1)]\n",
    "moving_mmsis[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<span style=\"color:black\">\n",
    "    <h3>Geospatial Functions in Redis</h3>\n",
    "    <p>GEOPOS, GEODIST, GEORADIUSBYMEMBER, GEOADD, GEOHASH, GEORADIUS</p>\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "r.geopos(\"moving\", moving_mmsis[10])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "r.geodist(\"moving\", moving_mmsis[10], moving_mmsis[11], unit=\"mi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "r.georadiusbymember(\"moving\", moving_mmsis[10], 3, unit=\"mi\", withdist=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "r.georadiusbymember(\"all\", moving_mmsis[10], 3, unit=\"mi\", withdist=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<span style=\"color:blue\">\n",
    "    <h2><b>Map Vessel Locations</b></h2>\n",
    "</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<span style=\"color:black\">\n",
    "    <h3>Read the shapefile for Puget Sound shipping lanes with GeoPandas</h3>\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "sss = gpd.read_file('/media/rock/x/data/ais_20180921/shapefiles/shiplanes_puget/shiplanes_puget.shp')\n",
    "# The US Shiplanes shapefile has been cut to (lat BETWEEN 47 AND 49.45) AND (lon BETWEEN -123.75 AND -122)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def map_shipping_lanes(mmsi, zoom=11):\n",
    "    \"\"\"\n",
    "    Creates a leaflet map, with shipping lanes and stationary vessels (white circles)\n",
    "    \"\"\"\n",
    "    vessel_location = r.geopos(\"moving\", mmsi)[0]\n",
    "    m = Map(center=(vessel_location[1], vessel_location[0]), zoom=zoom)\n",
    "    m.layout.width = '65%'\n",
    "    m.layout.height = '1000px'\n",
    "    m.add_layer(esri_satellite_layer)\n",
    "    m.add_control(LayersControl())\n",
    "    \n",
    "    # Precautionary Areas\n",
    "    precAreas_gs = sss[sss.OBJL == '96'].geometry  \n",
    "    num_precAreas = len(precAreas_gs)\n",
    "    precAreas = [None] * num_precAreas\n",
    "    for i in range(num_precAreas):\n",
    "        precAreas[i] = [(((precAreas_gs.iloc[i]).exterior.coords)[k][1], ((precAreas_gs.iloc[i]).exterior.coords)[k][0]) for k in range(len((precAreas_gs.iloc[i]).exterior.coords))]\n",
    "    \n",
    "    # Traffic Separation Schemes\n",
    "    sepSchemes_gs = sss[sss.OBJL == '150'].geometry\n",
    "    num_sepSchemes = len(sepSchemes_gs)\n",
    "    sepSchemes = [None] * num_sepSchemes\n",
    "    for i in range(num_sepSchemes):\n",
    "        sepSchemes[i] = [(((sepSchemes_gs.iloc[i]).exterior.coords)[k][1], ((sepSchemes_gs.iloc[i]).exterior.coords)[k][0]) for k in range(len((sepSchemes_gs.iloc[i]).exterior.coords))]\n",
    "    \n",
    "    # Shipping Lanes\n",
    "    shiplanes_gs = sss[(sss.OBJL == '148') | (sss.OBJL == '152')].geometry\n",
    "    num_shiplanes = len(shiplanes_gs)\n",
    "    shiplanes = [None] * num_shiplanes\n",
    "    for i in range(num_shiplanes):\n",
    "        shiplanes[i] = [(((shiplanes_gs.iloc[i]).exterior.coords)[k][1], ((shiplanes_gs.iloc[i]).exterior.coords)[k][0]) for k in range(len((shiplanes_gs.iloc[i]).exterior.coords))]\n",
    "    \n",
    "    colors = Blues10_4.hex_colors\n",
    "    precAreas_polygons_list = [Polygon(locations=precAreas[i], color='red', weight=5, fill_color='red') for i in range(num_precAreas)]\n",
    "    sepSchemes_polygons_list = [Polygon(locations=sepSchemes[i], color='black', weight=1, fill_color='blue', fill_opacity=0.7) for i in range(num_sepSchemes)]\n",
    "    shiplanes_polygons_list = [Polygon(locations=shiplanes[i], color='black', weight=1, fill_color=colors[2], fill_opacity=0.7) for i in range(num_shiplanes)]  # fill_color=colors[i % 8]\n",
    "    \n",
    "    precAreas_layer_group = LayerGroup(layers=tuple(precAreas_polygons_list))\n",
    "    sepSchemes_layer_group = LayerGroup(layers=tuple(sepSchemes_polygons_list))\n",
    "    shiplanes_layer_group = LayerGroup(layers=tuple(shiplanes_polygons_list))\n",
    "    m.add_layer(precAreas_layer_group)\n",
    "    m.add_layer(sepSchemes_layer_group)\n",
    "    m.add_layer(shiplanes_layer_group)\n",
    "    \n",
    "    # Add stationary vessels\n",
    "    stat_mmsis = [mmsi.decode(\"utf-8\") for mmsi in r.zrange(\"stationary\", 0, -1)]\n",
    "    stat_latlons = r.geopos(\"stationary\", *stat_mmsis)\n",
    "    stat_vessels = [Circle(location=(stat_latlons[i][1], stat_latlons[i][0]), radius=30, color='white', weight=2, fill_color='white', fill_opacity=0.6) for i in range(len(stat_latlons))] # radius in meters, not pixels\n",
    "    stat_layer_group = LayerGroup(layers=tuple(stat_vessels))\n",
    "    m.add_layer(stat_layer_group)\n",
    "    \n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "map_shipping_lanes(moving_mmsis[10], 11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<span style=\"color:black\">\n",
    "    <h3>Use GEOPOS to get the latitude and longitude of moving vessels</h3>\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def map_moving_vessels(mmsi, zoom=11):\n",
    "    \"\"\"\n",
    "    Adds moving vessels (speed > 4 knots) as magenta circles\n",
    "    \"\"\"\n",
    "    m = map_shipping_lanes(mmsi, zoom=zoom)\n",
    "    # Add moving vessels\n",
    "    moving_latlons = r.geopos(\"moving\", *moving_mmsis)\n",
    "    moving_vessels = [Circle(location=(moving_latlons[i][1], moving_latlons[i][0]), radius=120, color='magenta', weight=2, fill_color='magenta', fill_opacity=0.6) for i in range(len(moving_latlons))] # radius in meters, not pixels\n",
    "    moving_layer_group = LayerGroup(layers=tuple(moving_vessels))\n",
    "    m.add_layer(moving_layer_group)\n",
    "    \n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "map_moving_vessels(moving_mmsis[10], zoom=11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<span style=\"color:darkred\">\n",
    "    <h1><b>Redis Modules</b></h1>\n",
    "    <h3>RediSearch, RedisTimeSeries, RedisAI</h3>\n",
    "</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### Loading Modules:\n",
    "\n",
    "#### 1. From python:   \n",
    "os.system(\"redis-server --loadmodule ./redisearch.so\")  \n",
    "\n",
    "\n",
    "#### 2. From the configuration file /etc/redis/redis.conf  \n",
    "loadmodule /path/to/redisearch.so  \n",
    "\n",
    "\n",
    "#### 3. From the CLI (redis-cli)  \n",
    "127.0.0.6379> MODULE load /path/to/redisearch.so  \n",
    "\n",
    "https://oss.redislabs.com/redisearch/Commands.html#ftsearch  \n",
    "\n",
    "https://oss.redislabs.com/redisearch/Query_Syntax.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<span style=\"color:blue\">\n",
    "    <h2><b>RediSearch</b></h2>\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from redisearch import Client, TextField, NumericField, Query\n",
    "\n",
    "# Creating a client with a index name, metadataIndex\n",
    "meta = Client('metadataIndex')\n",
    "\n",
    "# Creating the index definition and schema\n",
    "meta.create_index([TextField('vessel_group'), NumericField('length'), NumericField('width'), NumericField('draft')])  # DO NOT DELETE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<span style=\"color:black\">\n",
    "    <h3>Add Documents to the Search Index from Metadata</h3>\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# DO NOT RUN if the Index & Keys have been created\n",
    "for row in range(len(vessels.index)):\n",
    "    meta.add_document(doc_id=\"meta_\"+str(vessels['mmsi'].iloc[row]), replace=True, \n",
    "                      vessel_group=vessels['vessel_group'].iloc[row] if str(vessels['vessel_group'].iloc[row]) != 'nan' else 'unknown',\n",
    "                      length=vessels['l'].iloc[row] if not np.isnan(vessels['l'].iloc[row]) else -999,\n",
    "                      width=vessels['w'].iloc[row] if not np.isnan(vessels['w'].iloc[row]) else -999,\n",
    "                      draft=vessels['draft'].iloc[row] if not np.isnan(vessels['draft'].iloc[row]) else -999)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<span style=\"color:black\">\n",
    "    <h3>Query the Search Index</h3>\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "results = {vg:meta.search(Query(vg).no_content().paging(0,5000)).docs for vg in vgroups}\n",
    "vg2mmsiList = {vg:[doc.id[5:] for doc in results[vg]] for vg in vgroups}\n",
    "mmsi2vg = {mmsi:vg for vg in vgroups for mmsi in vg2mmsiList[vg]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "{vg:len(vg2mmsiList[vg]) for vg in vgroups}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<span style=\"color:black\">\n",
    "    <h3>Color-code moving vessels (passenger, cargo, fishing etc) using RediSearch query results</h3>\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "moving_mmsis = [mmsi.decode(\"utf-8\") for mmsi in r.zrange(\"moving\", 0, -1)]\n",
    "moving_mmsi_vgroups = [mmsi2vg.get(mmsi) for mmsi in moving_mmsis]\n",
    "moving_mmsi_colors = [vgroup2color[vg] for vg in moving_mmsi_vgroups]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def map_moving_vessels_by_color(mmsi, zoom=11):\n",
    "    m = map_shipping_lanes(mmsi, zoom=zoom)\n",
    "    # Add moving vessels\n",
    "    moving_latlons = r.geopos(\"moving\", *moving_mmsis)\n",
    "    moving_vessels = [Circle(location=(moving_latlons[i][1], moving_latlons[i][0]), radius=200, \n",
    "                             color=moving_mmsi_colors[i], weight=2, fill_color=moving_mmsi_colors[i], fill_opacity=0.8) for i in range(len(moving_latlons))]\n",
    "    moving_layer_group = LayerGroup(layers=tuple(moving_vessels))\n",
    "    m.add_layer(moving_layer_group)\n",
    "    \n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "map_moving_vessels_by_color(moving_mmsis[10], zoom=11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<span style=\"color:blue\">\n",
    "    <h2><b>Redis Time Series</b></h2>\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from redistimeseries.client import Client\n",
    "rts = Client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "v1h = vessels_one_hour(y, m, d, H, M, S)\n",
    "# v1h = vessels_one_hour(2017, 11, 3, 17, 58, 35)\n",
    "mmsi2latlon = {str(mmsi):(v1h.loc[v1h['mmsi'] == int(mmsi)]['lat'].values, v1h.loc[v1h['mmsi'] == int(mmsi)]['lon'].values) for mmsi in moving_mmsis}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<span style=\"color:black\">\n",
    "    <h3>Create Keys to hold the Time Series data with 1 hour retention</h3>\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# DO NOT RUN if Keys exist\n",
    "for mmsi in moving_mmsis:\n",
    "    rts.create(\"ts_lat_\" + mmsi, retention_msecs=3600000, labels={'Time':'Lat'})\n",
    "    rts.create(\"ts_lon_\" + mmsi, retention_msecs=3600000, labels={'Time':'Lon'})\n",
    "    \n",
    "# r.keys(pattern=u'ts_lat*')\n",
    "# rts.get('ts_lat_' + mmsis[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# DO NOT RUN if Keys exist\n",
    "for mmsi in moving_mmsis:\n",
    "    v1h_subset = v1h.loc[v1h['mmsi'] == int(mmsi)]\n",
    "    lats = v1h_subset['lat'].values\n",
    "    lons = v1h_subset['lon'].values\n",
    "    time = v1h_subset['localtime']\n",
    "    for i in range(len(lats)):\n",
    "        rts.add(\"ts_lat_\" + mmsi, int(time.iloc[i].timestamp())*1000, lats[i])\n",
    "        rts.add(\"ts_lon_\" + mmsi, int(time.iloc[i].timestamp())*1000, lons[i])\n",
    "        \n",
    "# time is UNIX timestamp in milliseconds\n",
    "# YES, time = v1h_subset['localtime'] is a pandas series of type pd.Timestamp. Then int(time.iloc[i].timestamp())\n",
    "# NO, time = v1h_subset['localtime'].apply(lambda lt: int(lt.timestamp())) seems to be the same as above, but we get an int64 type, which is not accepted\n",
    "# NO, time = v1h_subset['localtime'].apply(lambda lt: int(lt.timestamp())).values. The array has type np.datetime64, which is not accepted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<span style=\"color:black\">\n",
    "    <h3>Map Vessel Tracks with RedisTimeSeries</h3>\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def map_vessel_tracks_redis_ts(mmsi, zoom=11):\n",
    "    m = map_moving_vessels_by_color(mmsi, zoom=zoom)\n",
    "    mmsi2lats = {mmsi:[float(tup[1]) for tup in rts.range(key='ts_lat_' + mmsi, from_time='0', to_time='+')] for mmsi in moving_mmsis}\n",
    "    mmsi2lons = {mmsi:[float(tup[1]) for tup in rts.range(key='ts_lon_' + mmsi, from_time='0', to_time='+')] for mmsi in moving_mmsis}\n",
    "    vessel_tracks = [Polyline(locations=[[mmsi2lats[moving_mmsis[j]][i], mmsi2lons[moving_mmsis[j]][i]] for i in range(len(mmsi2lats[moving_mmsis[j]]))], \n",
    "                      color=moving_mmsi_colors[j], fill_color=moving_mmsi_colors[j], fill_opacity=0.0) for j in range(len(moving_mmsis))]\n",
    "    tracks_layer_group = LayerGroup(layers=tuple(vessel_tracks))\n",
    "    m.add_layer(tracks_layer_group)\n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "map_vessel_tracks_redis_ts(moving_mmsis[10], zoom=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "outputs": [],
   "source": [
    "get_vessel_metadata(int(moving_mmsis[10]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<span style=\"color:blue\">\n",
    "    <h2><b>RedisAI</b></h2>\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from redisai import Client, DType, Tensor, Backend, Device\n",
    "# import ml2rt\n",
    "client = Client()\n",
    "# https://oss.redislabs.com/redisai/  # docs\n",
    "# https://github.com/RedisAI/redisai-py  # good\n",
    "# https://github.com/RedisAI/RedisAI\n",
    "# https://github.com/RedisAI/redisai-examples\n",
    "\n",
    "# https://pypi.org/project/ml2rt/\n",
    "# ML utilities: Converting models (sparkml, sklearn, xgboost to ONNX), serializing models to disk, loading it back to redisai-py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<span style=\"color:black\">\n",
    "    <h3>Load the Backend Runtime</h3>\n",
    "    <h4>using redisai-py or redis-cli</h4>\n",
    "</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<span style=\"color:black\">\n",
    "    <ul>\n",
    "    <li>client.loadbackend('TORCH', '/home/rock/git/RedisAI/install-cpu/backends/redisai_torch/redisai_torch.so')</li>\n",
    "    <li>client.loadbackend('TF', '/home/rock/git/RedisAI/install-cpu/backends/redisai_tensorflow/redisai_tensorflow.so')</li>\n",
    "    <li>client.loadbackend('ONNX', '/home/rock/git/RedisAI/install-cpu/backends/redisai_onnxruntime/redisai_onnxruntime.so')</li>\n",
    "    </ul>\n",
    "    <p>&dollar; redis-cli AI.CONFIG LOADBACKEND TF /home/rock/git/RedisAI/install-cpu/backends/redisai_tensorflow/redisai_tensorflow.so</p>\n",
    "    <p>&dollar; redis-cli -x AI.MODELSET foo TF CPU INPUTS a b OUTPUTS c < test/test_data/graph.pb</p>\n",
    "</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<span style=\"color:black\">\n",
    "    <h3>(Convert) and Load the Model with ml2rt</h3>\n",
    "</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<span style=\"color:black\">\n",
    "<p>model = ml2rt.load_model('/home/rock/git/RedisAI/test/test_data/graph.pb')</p>\n",
    "<p>client.modelset('m', Backend.tf, Device.cpu, inputs=['input_1', 'input_2'], outputs='output', data=model)</p>\n",
    "<p># ?client.modelset</p>\n",
    "</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<span style=\"color:black\">\n",
    "    <h3>Get the (naive) predicted tracks for the next 5 minutes</h3>\n",
    "</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# This does not use RedisAI yet. It estimates the 5-minute position using the geodesic distance in geopy\n",
    "# from geopy.distance import distance\n",
    "vm_moving['dest'] = vm_moving.apply(lambda row: distance(miles=row.sog * 5/60 * 1.15078).destination((row.lat, row.lon), row.cog), axis=1)\n",
    "\n",
    "# lat2,lon2,_ = distance(miles=distMiles).destination((lat1, lon1), bearing)\n",
    "# 1 knot = 1.15078 miles/hour\n",
    "# ~/anaconda3/lib/python3.7/site-packages/geopy/distance.py  # bearing is in degrees, not radians"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def map_predicted_track(mmsi, zoom=11):\n",
    "    m = map_shipping_lanes(mmsi, zoom=11)\n",
    "    # Add moving vessels\n",
    "    moving_latlons = r.geopos(\"moving\", *moving_mmsis)\n",
    "    moving_vessels = [Rectangle(bounds=((moving_latlons[i][1]-0.0010, moving_latlons[i][0]-0.0015), (moving_latlons[i][1]+0.0010, moving_latlons[i][0]+0.0015)),\n",
    "                               color=moving_mmsi_colors[i], weight=2, fill_color=moving_mmsi_colors[i], fill_opacity=0.8) for i in range(len(moving_latlons))]\n",
    "    moving_layer_group = LayerGroup(layers=tuple(moving_vessels))\n",
    "    m.add_layer(moving_layer_group)\n",
    "    predicted_tracks = [Polyline(locations=[[vm_moving[vm_moving['mmsi'] == int(moving_mmsis[j])]['lat'].iloc[0],vm_moving[vm_moving['mmsi'] == int(moving_mmsis[j])]['lon'].iloc[0]], \n",
    "                                            [vm_moving[vm_moving['mmsi'] == int(moving_mmsis[j])]['dest'].iloc[0][0],vm_moving[vm_moving['mmsi'] == int(moving_mmsis[j])]['dest'].iloc[0][1]]], \n",
    "                                 color=moving_mmsi_colors[j], fill_color=moving_mmsi_colors[j], fill_opacity=0.0) for j in range(len(moving_mmsis))]\n",
    "    pred_tracks_layer_group = LayerGroup(layers=tuple(predicted_tracks))\n",
    "    m.add_layer(pred_tracks_layer_group)\n",
    "    \n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "map_predicted_track(moving_mmsis[10], zoom=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "rise": {
   "scroll": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
